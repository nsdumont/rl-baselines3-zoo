"""This file just serves as an example on how to configure the zoo
using python scripts instead of yaml files."""
import torch
import hrr_gym_wrappers



hyperparams = {
    "CartPole-v1": dict(
        env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 161}}],
        n_envs=8,
        n_timesteps=1e5,
        policy="MlpPolicy",
        batch_size=256,
        n_steps=32,
        gamma=0.98,
        learning_rate=0.001,
        ent_coef=0.0,
        clip_range=0.2,
        n_epochs=20,
        gae_lambda=0.8,
    ),
    "Pendulum-v1": dict(
        env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 201}}],
        n_envs=4,
        n_timesteps=1e5,
        policy="MlpPolicy",
        n_steps= 1024,
        gae_lambda= 0.95,
        gamma= 0.9,
        n_epochs= 10,
        ent_coef= 0.0,
        learning_rate= 1e-3,
        clip_range= 0.2,
        use_sde= True,
        sde_sample_freq= 4,
    ),
    "MountainCar-v0": dict(
       env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 97}}],
      n_envs= 16,
      n_timesteps= 1e6,
      policy= 'MlpPolicy',
      n_steps= 16,
      gae_lambda= 0.98,
      gamma= 0.99,
      n_epochs= 4,
      ent_coef= 0.0
      ),
    "MountainCarContinuous-v0": dict(
    env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 97}}],
      normalize= True,
      n_envs= 1,
      n_timesteps= 20000,
      policy= 'MlpPolicy',
      batch_size= 256,
      n_steps= 8,
      gamma= 0.9999,
      learning_rate= 7.77e-05,
      ent_coef= 0.00429,
      clip_range= 0.1,
      n_epochs= 10,
      gae_lambda= 0.9,
      max_grad_norm= 5,
      vf_coef= 0.19,
      use_sde= True,
      policy_kwargs= "dict(log_std_init=-3.29, ortho_init=False)"
      ),
    "LunarLander-v2": dict(
    env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 289}}],
      n_envs= 16,
      n_timesteps= 1e6,
      policy= 'MlpPolicy',
      n_steps= 1024,
      batch_size= 64,
      gae_lambda= 0.98,
      gamma= 0.999,
      n_epochs= 4,
      ent_coef= 0.01,
      ),
    "LunarLanderContinuous-v2": dict(
      env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 289}}],
      n_envs= 16,
      n_timesteps= 1e6,
      policy= 'MlpPolicy',
      n_steps= 1024,
      batch_size= 64,
      gae_lambda= 0.98,
      gamma= 0.999,
      n_epochs= 4,
      ent_coef= 0.01,
      ),
    "Acrobot-v1": dict(
      env_wrapper=[{"hrr_gym_wrappers.RandObsWrapper": {"shape_out": 225}}],
      normalize= True,
      n_envs= 16,
      n_timesteps= 1e6,
      policy= 'MlpPolicy',
      n_steps= 256,
      gae_lambda= 0.94,
      gamma= 0.99,
      n_epochs= 4,
      ent_coef= 0.0,
      ),
}

