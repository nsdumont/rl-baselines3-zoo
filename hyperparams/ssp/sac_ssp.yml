LunarLanderContinuous-v2:
  batch_size: 256
  buffer_size: 1000000
  ent_coef: auto
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 451
  gamma: 0.99
  gradient_steps: 1
  learning_rate: lin_7.3e-4
  learning_starts: 10000
  n_timesteps: 500000.0
  policy: MlpPolicy
  policy_kwargs: dict(net_arch=[400, 300])
  tau: 0.01
  train_freq: 1
  
MountainCarContinuous-v0:
  batch_size: 512
  buffer_size: 50000
  ent_coef: 0.1
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 151
      length_scale: [0.34728204118474704, 0.15569961421392498]
  gamma: 0.9999
  gradient_steps: 32
  learning_rate: 0.0003
  learning_starts: 0
  n_timesteps: 50000.0
  policy: MlpPolicy
  policy_kwargs: "dict(log_std_init=-3.67, net_arch=[64, 64])"
  tau: 0.01
  train_freq: 32
  use_sde: true
  
Pendulum-v1:
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 201
  learning_rate: 0.001
  n_timesteps: 20000
  policy: MlpPolicy


##
ContinuousMaze-5x5-v0: &conmaze-defaults
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 151
      length_scale: [1.0000000, 1.0000000]
  n_timesteps: !!float 1e5
  policy: 'MlpPolicy'
  learning_rate: !!float 3e-4
  buffer_size: 10000
  batch_size: 512
  ent_coef: 0.1
  train_freq: 32
  gradient_steps: 32
  gamma: 0.9999
  tau: 0.01
  learning_starts: 0
  use_sde: True
  policy_kwargs: "dict(log_std_init=-3.67, net_arch=[64, 64])"
  
                       
ContinuousMaze-6x6-v0:
  <<: *conmaze-defaults
  
ContinuousMaze-7x7-v0:
  <<: *conmaze-defaults
  
ContinuousMaze-8x8-v0:
  <<: *conmaze-defaults
  
ContinuousMaze-9x9-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMaze-10x10-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMaze-11x11-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMaze-12x12-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMaze-15x15-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 5e5
  
ContinuousMaze-20x20-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 1e6
  
  

ContinuousMazeBlocks-5x5-v0:
  <<: *conmaze-defaults
  
ContinuousMazeBlocks-6x6-v0:
  <<: *conmaze-defaults
  
ContinuousMazeBlocks-7x7-v0:
  <<: *conmaze-defaults
  
ContinuousMazeBlocks-8x8-v0:
  <<: *conmaze-defaults
  
ContinuousMazeBlocks-9x9-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMazeBlocks-10x10-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMazeBlocks-11x11-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMazeBlocks-12x12-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 3e5
  
ContinuousMazeBlocks-15x15-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 5e5
  
ContinuousMazeBlocks-19x19-v0:
  <<: *conmaze-defaults
  n_timesteps: !!float 1e6
  
GoalContinuousMaze-5x5-v0: &goalconmaze-defaults
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 151
      length_scale: [1.0000000, 1.0000000]
  n_timesteps: !!float 1e5
  policy: 'MultiInputPolicy'
  buffer_size: 10000
  ent_coef: 'auto'
  batch_size: 256
  gamma: 0.95
  learning_rate: 0.001
  learning_starts: 0
  normalize: True
  replay_buffer_class: HerReplayBuffer
  replay_buffer_kwargs: "dict(
    goal_selection_strategy='future',
    n_sampled_goal=4
  )"
  policy_kwargs: "dict(net_arch=[64, 64])"
  
GoalContinuousMaze-6x6-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMaze-7x7-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMaze-8x8-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMaze-9x9-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMaze-10x10-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMaze-11x11-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMaze-12x12-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMaze-15x15-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 5e5
  
GoalContinuousMaze-20x20-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 1e6
  
  

GoalContinuousMazeBlocks-5x5-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMazeBlocks-6x6-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMazeBlocks-7x7-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMazeBlocks-8x8-v0:
  <<: *goalconmaze-defaults
  
GoalContinuousMazeBlocks-9x9-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMazeBlocks-10x10-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMazeBlocks-11x11-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMazeBlocks-12x12-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 3e5
  
GoalContinuousMazeBlocks-15x15-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 5e5
  
GoalContinuousMazeBlocks-19x19-v0:
  <<: *goalconmaze-defaults
  n_timesteps: !!float 1e6