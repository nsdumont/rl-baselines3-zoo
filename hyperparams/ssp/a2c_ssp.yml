Acrobot-v1:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 351
  n_envs: 16
  n_timesteps: 500000.0
  normalize: true
  policy: MlpPolicy
CartPole-v1:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 251
  n_envs: 8
  n_timesteps: 500000.0
  policy: MlpPolicy
LunarLander-v2:
  ent_coef: 1.0e-05
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 451
  gamma: 0.995
  learning_rate: lin_0.00083
  n_envs: 8
  n_steps: 5
  n_timesteps: 200000.0
  policy: MlpPolicy
  
LunarLanderContinuous-v2:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 451
  gae_lambda: 0.9
  gamma: 0.99
  learning_rate: lin_7e-4
  max_grad_norm: 0.5
  n_envs: 4
  n_steps: 8
  n_timesteps: 5000000.0
  normalize: true
  normalize_advantage: false
  policy: MlpPolicy
  policy_kwargs: dict(log_std_init=-2, ortho_init=False)
  use_rms_prop: true
  use_sde: true
  vf_coef: 0.4
  
MountainCar-v0:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 151
  n_envs: 16
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  
MountainCarContinuous-v0:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 151
  n_envs: 4
  n_steps: 100
  n_timesteps: 100000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(log_std_init=0.0, ortho_init=False)
  sde_sample_freq: 16
  use_sde: true
  
Pendulum-v1:
  ent_coef: 0.0
  env_wrapper:
  - hrr_gym_wrappers.SSPObsWrapper:
      shape_out: 201
  gae_lambda: 0.9
  gamma: 0.9
  learning_rate: lin_7e-4
  max_grad_norm: 0.5
  n_envs: 8
  n_steps: 8
  n_timesteps: 1000000.0
  normalize: true
  normalize_advantage: false
  policy: MlpPolicy
  policy_kwargs: dict(log_std_init=-2, ortho_init=False)
  use_rms_prop: true
  use_sde: true
  vf_coef: 0.4


MiniGrid-DoorKey-5x5-v0:
  env_wrapper: 
  - hrr_gym_wrappers.SSPMiniGridViewFlatWrapper:
      shape_out: 129
  n_envs: 2
  n_steps: 25
  learning_rate: 0.001
  ent_coef: 0.001
  n_timesteps: !!float 5e4
  max_grad_norm: 10
  policy: MlpPolicy
  policy_kwargs: "dict(features_extractor_class=MlpFeaturesExtractor, features_extractor_kwargs=dict(features_dim=64,net_arch=[64],activation_fn=nn.ReLU), net_arch=dict(pi=[64], vf=[64]),activation_fn=nn.ReLU)"