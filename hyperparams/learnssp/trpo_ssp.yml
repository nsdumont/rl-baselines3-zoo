Acrobot-v1:
  n_envs: 2
  n_steps: 1024
  n_timesteps: 100000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=351))
Ant-v4:
  batch_size: 128
  cg_damping: 0.1
  cg_max_steps: 25
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=501,basis_type="rand"))
  sub_sampling_factor: 1
CartPole-v1:
  batch_size: 512
  cg_damping: 0.001
  gae_lambda: 0.98
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 512
  n_timesteps: 100000.0
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=251))
HalfCheetah-v4:
  batch_size: 128
  cg_damping: 0.1
  cg_max_steps: 25
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=501,basis_type="rand"))
  sub_sampling_factor: 1
  target_kl: 0.04
Hopper-v4:
  batch_size: 128
  cg_damping: 0.1
  cg_max_steps: 25
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=501,basis_type="rand"))
  sub_sampling_factor: 1
LunarLander-v2:
  cg_damping: 0.01
  gae_lambda: 0.98
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 15
  n_envs: 2
  n_steps: 512
  n_timesteps: 200000.0
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=451))
LunarLanderContinuous-v2:
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 100000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=451))
MountainCar-v0:
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 100000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=151))
MountainCarContinuous-v0:
  n_envs: 2
  n_timesteps: 50000
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=151))
  sde_sample_freq: 4
  use_sde: true
Pendulum-v1:
  gamma: 0.9
  n_critic_updates: 15
  n_envs: 2
  n_steps: 1024
  n_timesteps: 100000.0
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=201))
  sde_sample_freq: 4
  use_sde: true
Swimmer-v4:
  batch_size: 128
  cg_damping: 0.1
  cg_max_steps: 25
  gae_lambda: 0.95
  gamma: 0.9999
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=501,basis_type="rand"))
  sub_sampling_factor: 1
Walker2d-v4:
  batch_size: 128
  cg_damping: 0.1
  cg_max_steps: 25
  gae_lambda: 0.95
  gamma: 0.99
  learning_rate: 0.001
  n_critic_updates: 20
  n_envs: 2
  n_steps: 1024
  n_timesteps: 1000000.0
  normalize: true
  policy: MlpPolicy
  policy_kwargs: dict(features_extractor_class=hrr_gym_wrappers.SSPProcesser,features_extractor_kwargs=dict(features_dim=501,basis_type="rand"))
  sub_sampling_factor: 1
